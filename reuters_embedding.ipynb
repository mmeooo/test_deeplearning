{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reuters_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvpFWTJBKF3p2GALmJeXFM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjIDb7pcXMvf"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odc0wQA2XTHU",
        "outputId": "07f8d60e-58a8-4834-926d-8d09864c0941"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.reuters.load_data(num_words=10000)\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:144: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982,), (8982,), (2246,), (2246,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SPfS_GnXXIY",
        "outputId": "aa0d6d82-ff4d-4c4f-b147-0d3348bdab67"
      },
      "source": [
        "print(type(x_train), type(x_train[0]))\n",
        "print(x_train[3])\n",
        "len(x_train[3])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'list'>\n",
            "[1, 4, 686, 867, 558, 4, 37, 38, 309, 2276, 465, 893, 3541, 114, 2902, 69, 312, 35, 15, 7, 335, 1679, 21, 25, 3675, 2, 3498, 58, 69, 68, 493, 5, 25, 465, 377, 2430, 4, 293, 1172, 739, 4379, 8, 7, 1510, 1131, 13, 899, 6, 4, 990, 309, 415, 4519, 6920, 645, 3916, 791, 5, 4379, 75, 8, 24, 10, 1311, 4677, 5, 344, 756, 7, 2, 231, 9691, 2603, 1413, 43, 509, 43, 68, 327, 5, 2, 3498, 297, 638, 73, 430, 22, 4, 580, 7, 48, 41, 30, 2, 136, 4, 344, 298, 4, 580, 40, 344, 5078, 2, 291, 1488, 10, 3148, 5, 231, 6250, 1308, 5, 8250, 7043, 21, 2, 1622, 990, 309, 415, 265, 5992, 8945, 1149, 9118, 2, 4, 344, 9691, 756, 3729, 2, 4667, 2, 3249, 28, 10, 2190, 24, 77, 41, 682, 10, 4851, 2048, 7, 4, 5540, 2926, 1598, 22, 370, 5954, 7541, 5, 54, 5232, 1685, 2916, 10, 1571, 946, 60, 51, 3249, 5249, 4, 73, 2135, 669, 4, 580, 64, 10, 4280, 6, 2, 25, 482, 35, 150, 377, 2430, 7, 10, 2, 836, 2, 4730, 6920, 5, 4379, 2, 2, 3541, 8, 4, 344, 291, 2, 298, 4228, 6, 2223, 24, 2, 41, 343, 430, 210, 6, 3498, 297, 64, 10, 2281, 455, 5, 7003, 125, 222, 17, 12]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "224"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzVi7vw5XXFe",
        "outputId": "e6fad678-54bd-4a1b-99b6-22c4fa117c01"
      },
      "source": [
        "print(type(y_train), type(y_train[0]))\n",
        "print(y_train[3])\n",
        "print(y_train[0:5])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.int64'>\n",
            "4\n",
            "[3 4 3 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxaDVtuEXXDw",
        "outputId": "ec3a3dec-39b2-4251-f3eb-7eccb87a9c72"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.unique(y_train) # 장르 데이터"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeSoLyjZXXA0",
        "outputId": "bf0dabd3-e135-4507-a043-de9c56669e8c"
      },
      "source": [
        "word_index = tf.keras.datasets.imdb.get_word_index()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8rmMAS4XW-c"
      },
      "source": [
        "invert_word_index = dict()\n",
        "\n",
        "for (key, value) in word_index.items():\n",
        "  invert_word_index[value] = key"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "QtPq_NHqXW7v",
        "outputId": "90ec585c-a579-4903-f9bb-1c7737ef428d"
      },
      "source": [
        "decode_str = str()\n",
        "\n",
        "for num in x_train[0]:\n",
        "  decode_str = decode_str + invert_word_index[num] + ' '  \n",
        "\n",
        "decode_str"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the and and in out i several to have always place to catholic plot with women horror made can br don't to film characters is film does for made can great you lead he br what of good in believable or comedy work is old is first this for you 10 this for br what it christians ideas they're is although is different this for you while has this for with in between military made can very all comedy at an say is being for movie that \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCUIcsbqai4b"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa-NLpzbXW5b",
        "outputId": "da5bed27-4ec1-4b5f-a364-995f1eff2276"
      },
      "source": [
        "len(x_train[0]), len(x_train[50]), len(x_train[500]), len(x_train[1000])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87, 118, 170, 626)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzpMolYJXW3Q",
        "outputId": "ffe7087c-98f7-4428-db9a-257da7b26c44"
      },
      "source": [
        "pad_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=1200)\n",
        "len(pad_x_train[0]), pad_x_train[0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, array([ 0,  0,  0, ..., 15, 17, 12], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slLJgvcjXW04",
        "outputId": "3c2a165a-7216-416b-940c-a0b32461bc07"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BPVzMxOe5ob"
      },
      "source": [
        "# Make model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dBpQ4E-XWyP"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(tf.keras.layers.Embedding(input_dim=10000, output_dim=24, input_length=1200))\n",
        "\n",
        "# Hidden Layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Output Layer\n",
        "model.add(tf.keras.layers.Dense(1, activation='softmax')) \n",
        "\n",
        "\n",
        "# Gadget\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) \n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5FpV9dYXWvc",
        "outputId": "be837266-18cd-4b2a-b6d5-3a5d9d78a7c7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1200, 24)          240000    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 28800)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 28801     \n",
            "=================================================================\n",
            "Total params: 268,801\n",
            "Trainable params: 268,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBrniaVKZMGa",
        "outputId": "564f0146-a430-4310-f112-07c4b5ebb938"
      },
      "source": [
        "hist = model.fit(pad_x_train, y_train, epochs=50, validation_split=0.3, batch_size=32)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "197/197 [==============================] - 3s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 2/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 3/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 4/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 5/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 6/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 7/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 8/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 9/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 10/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 11/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 12/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 13/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 14/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 15/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 16/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 17/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 18/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 19/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 20/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 21/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 22/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 23/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 24/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 25/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 26/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 27/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 28/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 29/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 30/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 31/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 32/50\n",
            "197/197 [==============================] - 2s 9ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 33/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 34/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 35/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 36/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 37/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 38/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 39/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 40/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 41/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 42/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 43/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 44/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 45/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 46/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 47/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 48/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 49/50\n",
            "197/197 [==============================] - 2s 11ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n",
            "Epoch 50/50\n",
            "197/197 [==============================] - 2s 10ms/step - loss: 0.0000e+00 - accuracy: 0.0482 - val_loss: 0.0000e+00 - val_accuracy: 0.0479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvsG1IBFfCNJ"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csxkoyIrZPG8",
        "outputId": "43884ca3-8af6-4e93-ff4a-c2e4f451788b"
      },
      "source": [
        "model.evaluate(pad_x_train, y_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "281/281 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0480961911380291]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMvFDTMgZWHq",
        "outputId": "668cd215-80e1-47f3-9750-24bb67a6649b"
      },
      "source": [
        "pad_x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=1200)\n",
        "len(pad_x_test[20])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEhd8LY-Zll3",
        "outputId": "5843c17b-e574-47ea-ef61-952beadf5f21"
      },
      "source": [
        "model.evaluate(pad_x_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GufUWJnqZq99"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}