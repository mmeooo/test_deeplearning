{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reuters_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeBu3stpQHLMeI4b8S0srI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjIDb7pcXMvf"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Odc0wQA2XTHU",
        "outputId": "cca6ef2a-387d-4a13-fc09-c5ee5a46d8bb"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.reuters.load_data(num_words=10000)\n",
        "\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:143: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/reuters.py:144: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8982,), (8982,), (2246,), (2246,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SPfS_GnXXIY",
        "outputId": "c427e0ba-bb69-4159-ff06-f7dac7944383"
      },
      "source": [
        "print(type(x_train), type(x_train[0]))\n",
        "print(x_train[3])\n",
        "len(x_train[3])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'list'>\n",
            "[1, 4, 686, 867, 558, 4, 37, 38, 309, 2276, 465, 893, 3541, 114, 2902, 69, 312, 35, 15, 7, 335, 1679, 21, 25, 3675, 2, 3498, 58, 69, 68, 493, 5, 25, 465, 377, 2430, 4, 293, 1172, 739, 4379, 8, 7, 1510, 1131, 13, 899, 6, 4, 990, 309, 415, 4519, 6920, 645, 3916, 791, 5, 4379, 75, 8, 24, 10, 1311, 4677, 5, 344, 756, 7, 2, 231, 9691, 2603, 1413, 43, 509, 43, 68, 327, 5, 2, 3498, 297, 638, 73, 430, 22, 4, 580, 7, 48, 41, 30, 2, 136, 4, 344, 298, 4, 580, 40, 344, 5078, 2, 291, 1488, 10, 3148, 5, 231, 6250, 1308, 5, 8250, 7043, 21, 2, 1622, 990, 309, 415, 265, 5992, 8945, 1149, 9118, 2, 4, 344, 9691, 756, 3729, 2, 4667, 2, 3249, 28, 10, 2190, 24, 77, 41, 682, 10, 4851, 2048, 7, 4, 5540, 2926, 1598, 22, 370, 5954, 7541, 5, 54, 5232, 1685, 2916, 10, 1571, 946, 60, 51, 3249, 5249, 4, 73, 2135, 669, 4, 580, 64, 10, 4280, 6, 2, 25, 482, 35, 150, 377, 2430, 7, 10, 2, 836, 2, 4730, 6920, 5, 4379, 2, 2, 3541, 8, 4, 344, 291, 2, 298, 4228, 6, 2223, 24, 2, 41, 343, 430, 210, 6, 3498, 297, 64, 10, 2281, 455, 5, 7003, 125, 222, 17, 12]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "224"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzVi7vw5XXFe",
        "outputId": "f2dc1430-57cf-4504-cf55-8fe508a4e153"
      },
      "source": [
        "print(type(y_train), type(y_train[0]))\n",
        "print(y_train[3])\n",
        "print(y_train[0:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'numpy.int64'>\n",
            "4\n",
            "[3 4 3 4 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxaDVtuEXXDw",
        "outputId": "4b39bde4-d149-4c60-d270-0a319cea1af7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.unique(y_train) # 장르 데이터"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeSoLyjZXXA0",
        "outputId": "51b54663-aa78-41c5-cb7a-be113c3467a6"
      },
      "source": [
        "word_index = tf.keras.datasets.imdb.get_word_index()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8rmMAS4XW-c"
      },
      "source": [
        "invert_word_index = dict()\n",
        "\n",
        "for (key, value) in word_index.items():\n",
        "  invert_word_index[value] = key"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "QtPq_NHqXW7v",
        "outputId": "696187c3-e24a-49ee-c774-6dec6011c2bd"
      },
      "source": [
        "decode_str = str()\n",
        "\n",
        "for num in x_train[0]:\n",
        "  decode_str = decode_str + invert_word_index[num] + ' '  \n",
        "\n",
        "decode_str"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the and and in out i several to have always place to catholic plot with women horror made can br don't to film characters is film does for made can great you lead he br what of good in believable or comedy work is old is first this for you 10 this for br what it christians ideas they're is although is different this for you while has this for with in between military made can very all comedy at an say is being for movie that \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCUIcsbqai4b"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa-NLpzbXW5b",
        "outputId": "7e32afb5-5013-478d-da22-ccd08a8eae85"
      },
      "source": [
        "len(x_train[0]), len(x_train[50]), len(x_train[500]), len(x_train[1000])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87, 118, 170, 626)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzpMolYJXW3Q",
        "outputId": "32b6102a-0413-417d-c3af-518553066cde"
      },
      "source": [
        "pad_x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=500)\n",
        "len(pad_x_train[0]), pad_x_train[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    1,    2,    2,    8,   43,\n",
              "          10,  447,    5,   25,  207,  270,    5, 3095,  111,   16,  369,\n",
              "         186,   90,   67,    7,   89,    5,   19,  102,    6,   19,  124,\n",
              "          15,   90,   67,   84,   22,  482,   26,    7,   48,    4,   49,\n",
              "           8,  864,   39,  209,  154,    6,  151,    6,   83,   11,   15,\n",
              "          22,  155,   11,   15,    7,   48,    9, 4579, 1005,  504,    6,\n",
              "         258,    6,  272,   11,   15,   22,  134,   44,   11,   15,   16,\n",
              "           8,  197, 1245,   90,   67,   52,   29,  209,   30,   32,  132,\n",
              "           6,  109,   15,   17,   12], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slLJgvcjXW04",
        "outputId": "e10472f2-1dd0-4a13-e0ca-74ea6523d91f"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BPVzMxOe5ob"
      },
      "source": [
        "# Make model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dBpQ4E-XWyP"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(tf.keras.layers.Embedding(input_dim=10000, output_dim=24, input_length=500))\n",
        "\n",
        "# Hidden Layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Output Layer\n",
        "model.add(tf.keras.layers.Dense(46, activation='softmax')) \n",
        "\n",
        "\n",
        "# Gadget\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5FpV9dYXWvc",
        "outputId": "f0b4da3c-f8d2-4ff8-b72a-08ba9340d368"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 24)           240000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12000)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 46)                552046    \n",
            "=================================================================\n",
            "Total params: 792,046\n",
            "Trainable params: 792,046\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBrniaVKZMGa",
        "outputId": "fae97cbf-8da0-4182-a230-69d42c23c1c1"
      },
      "source": [
        "hist = model.fit( pad_x_train, y_train, epochs=50, validation_split=0.3, batch_size=32 )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "197/197 [==============================] - 3s 14ms/step - loss: 2.1207 - accuracy: 0.4506 - val_loss: 1.6956 - val_accuracy: 0.5685\n",
            "Epoch 2/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 1.3374 - accuracy: 0.6695 - val_loss: 1.3948 - val_accuracy: 0.6635\n",
            "Epoch 3/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.7401 - accuracy: 0.8389 - val_loss: 1.2952 - val_accuracy: 0.6935\n",
            "Epoch 4/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.4180 - accuracy: 0.9170 - val_loss: 1.2861 - val_accuracy: 0.7013\n",
            "Epoch 5/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.2749 - accuracy: 0.9480 - val_loss: 1.3195 - val_accuracy: 0.7009\n",
            "Epoch 6/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.2016 - accuracy: 0.9598 - val_loss: 1.3486 - val_accuracy: 0.7020\n",
            "Epoch 7/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1624 - accuracy: 0.9637 - val_loss: 1.3932 - val_accuracy: 0.6983\n",
            "Epoch 8/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1460 - accuracy: 0.9672 - val_loss: 1.4039 - val_accuracy: 0.7009\n",
            "Epoch 9/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.1339 - accuracy: 0.9668 - val_loss: 1.4272 - val_accuracy: 0.6998\n",
            "Epoch 10/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1271 - accuracy: 0.9671 - val_loss: 1.4911 - val_accuracy: 0.6968\n",
            "Epoch 11/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1241 - accuracy: 0.9677 - val_loss: 1.4502 - val_accuracy: 0.7002\n",
            "Epoch 12/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1246 - accuracy: 0.9660 - val_loss: 1.4751 - val_accuracy: 0.7002\n",
            "Epoch 13/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1160 - accuracy: 0.9690 - val_loss: 1.4717 - val_accuracy: 0.6976\n",
            "Epoch 14/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1202 - accuracy: 0.9680 - val_loss: 1.4981 - val_accuracy: 0.6965\n",
            "Epoch 15/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1146 - accuracy: 0.9666 - val_loss: 1.4751 - val_accuracy: 0.7002\n",
            "Epoch 16/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.1123 - accuracy: 0.9677 - val_loss: 1.4457 - val_accuracy: 0.7061\n",
            "Epoch 17/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.1074 - accuracy: 0.9679 - val_loss: 1.4748 - val_accuracy: 0.7028\n",
            "Epoch 18/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.1106 - accuracy: 0.9664 - val_loss: 1.5314 - val_accuracy: 0.6994\n",
            "Epoch 19/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1040 - accuracy: 0.9687 - val_loss: 1.4692 - val_accuracy: 0.7065\n",
            "Epoch 20/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.1092 - accuracy: 0.9682 - val_loss: 1.4400 - val_accuracy: 0.7069\n",
            "Epoch 21/50\n",
            "197/197 [==============================] - 2s 13ms/step - loss: 0.1056 - accuracy: 0.9695 - val_loss: 1.4343 - val_accuracy: 0.7054\n",
            "Epoch 22/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.1041 - accuracy: 0.9668 - val_loss: 1.6097 - val_accuracy: 0.6913\n",
            "Epoch 23/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.1014 - accuracy: 0.9690 - val_loss: 1.4421 - val_accuracy: 0.7095\n",
            "Epoch 24/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.0983 - accuracy: 0.9691 - val_loss: 1.4707 - val_accuracy: 0.7054\n",
            "Epoch 25/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0990 - accuracy: 0.9696 - val_loss: 1.4622 - val_accuracy: 0.7065\n",
            "Epoch 26/50\n",
            "197/197 [==============================] - 2s 13ms/step - loss: 0.0999 - accuracy: 0.9671 - val_loss: 1.4391 - val_accuracy: 0.7106\n",
            "Epoch 27/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.1029 - accuracy: 0.9685 - val_loss: 1.4576 - val_accuracy: 0.7095\n",
            "Epoch 28/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0919 - accuracy: 0.9672 - val_loss: 1.5940 - val_accuracy: 0.6991\n",
            "Epoch 29/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.1017 - accuracy: 0.9669 - val_loss: 1.5221 - val_accuracy: 0.7054\n",
            "Epoch 30/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0939 - accuracy: 0.9685 - val_loss: 1.4531 - val_accuracy: 0.7117\n",
            "Epoch 31/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0905 - accuracy: 0.9688 - val_loss: 1.4876 - val_accuracy: 0.6994\n",
            "Epoch 32/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0903 - accuracy: 0.9679 - val_loss: 1.5661 - val_accuracy: 0.7072\n",
            "Epoch 33/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.0918 - accuracy: 0.9669 - val_loss: 1.4586 - val_accuracy: 0.7132\n",
            "Epoch 34/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0871 - accuracy: 0.9682 - val_loss: 1.4498 - val_accuracy: 0.7150\n",
            "Epoch 35/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.0921 - accuracy: 0.9674 - val_loss: 1.4967 - val_accuracy: 0.7135\n",
            "Epoch 36/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.0885 - accuracy: 0.9679 - val_loss: 1.4766 - val_accuracy: 0.7069\n",
            "Epoch 37/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0918 - accuracy: 0.9672 - val_loss: 1.5136 - val_accuracy: 0.7058\n",
            "Epoch 38/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.0870 - accuracy: 0.9676 - val_loss: 1.4611 - val_accuracy: 0.7109\n",
            "Epoch 39/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.0834 - accuracy: 0.9674 - val_loss: 1.5212 - val_accuracy: 0.7061\n",
            "Epoch 40/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0875 - accuracy: 0.9690 - val_loss: 1.5805 - val_accuracy: 0.6972\n",
            "Epoch 41/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.0834 - accuracy: 0.9698 - val_loss: 1.5350 - val_accuracy: 0.7091\n",
            "Epoch 42/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0856 - accuracy: 0.9680 - val_loss: 1.6085 - val_accuracy: 0.7009\n",
            "Epoch 43/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0798 - accuracy: 0.9690 - val_loss: 1.4854 - val_accuracy: 0.7132\n",
            "Epoch 44/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0843 - accuracy: 0.9676 - val_loss: 1.5113 - val_accuracy: 0.7080\n",
            "Epoch 45/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0812 - accuracy: 0.9683 - val_loss: 1.4996 - val_accuracy: 0.7098\n",
            "Epoch 46/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0802 - accuracy: 0.9680 - val_loss: 1.5971 - val_accuracy: 0.7020\n",
            "Epoch 47/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.0841 - accuracy: 0.9669 - val_loss: 1.5258 - val_accuracy: 0.7083\n",
            "Epoch 48/50\n",
            "197/197 [==============================] - 2s 12ms/step - loss: 0.0805 - accuracy: 0.9690 - val_loss: 1.6733 - val_accuracy: 0.7028\n",
            "Epoch 49/50\n",
            "197/197 [==============================] - 3s 13ms/step - loss: 0.0795 - accuracy: 0.9671 - val_loss: 1.5486 - val_accuracy: 0.7054\n",
            "Epoch 50/50\n",
            "197/197 [==============================] - 2s 13ms/step - loss: 0.0785 - accuracy: 0.9685 - val_loss: 1.5450 - val_accuracy: 0.7017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvsG1IBFfCNJ"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csxkoyIrZPG8",
        "outputId": "8b7da4b8-f0e2-492f-e634-0daa00490dd9"
      },
      "source": [
        "model.evaluate(pad_x_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "281/281 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.8948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5002304315567017, 0.8947895765304565]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMvFDTMgZWHq",
        "outputId": "dfe7e3ce-316e-45f1-8c95-74f596d7c76e"
      },
      "source": [
        "pad_x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=500)\n",
        "len(pad_x_test[20])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEhd8LY-Zll3",
        "outputId": "0102f747-951e-4652-ea03-bc73f99934b1"
      },
      "source": [
        "model.evaluate(pad_x_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GufUWJnqZq99"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}